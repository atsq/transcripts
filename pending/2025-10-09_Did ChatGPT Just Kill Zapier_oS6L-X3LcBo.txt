Well, OpenAI just did it again. Their
latest releases just disrupted a ton of
businesses. ChatGpt just rolled out a
new feature that makes it so you never
need to leave their app. And OpenAI also
shipped agent Kit, a tool that makes it
simple for anyone to build agents, and
they made them all available to
everyone. So, in this video, I'm going
to break it all down. I'm going to share
how to use them, and I'm going to give
my thoughts on what all of this means.
So, let's go ahead and dive right in.
Monday, October 6th. The day I'm
recording this video was OpenAI's dev
day. And since we got the new Sora 2
last week, everyone was wondering what
the heck is OpenAI going to announce
this week. Well, here's the quick TL
didn't watch of what was announced. It
was mostly features for developers like
GPT5 Pro, Realtime Mini, and the new
Sora 2. It was announced were all made
available inside the API. Codeex got
some improvements and a Slack
integration. They added some small bits
of polish to their platform and
enterprise controls and a handful of
other things that will make developers
lives easier. But the two things that
really impressed me and the things that
most people are out there talking about
right now are the abilities to call upon
apps and use them directly inside of
chat GPT and the new AI agent builder
called agent kit. So let's focus on
those two things. Starting with apps
inside of chat GPT. So the new ability
to use apps inside of chat GPT is really
simple. You can just call upon the apps.
So let's say for instance I want to
create a Spotify playlist. I can say
something inside of chat GPT like use
I'll use the at symbol Spotify. And you
can see it automatically found Spotify
and it added it as a tool that I'm going
to use. But let's go ahead and type use
Spotify to create a playlist of music
similar to Bloop 182. Now, if I submit
this, it'll say connecting to the app.
And then it'll ask me to actually
connect over to Spotify. So, if I click
continue, agree to their terms here.
Agree once again. And now Spotify is
connected. This is assuming you're
already logged in to Spotify. If you
weren't logged in, you would probably
need to log in. A few seconds later,
I've got a playlist called Rock Songs
Like Blink182. It starts with a Blink182
song and then goes into other similar
bands. And if I click on open in
Spotify, I can jump straight to this
playlist that it created for me with all
of the songs that are similar to
Blink182 songs, including a few actually
from Blink182. If we take a peek over at
the press release on the OpenAI website
where they introduced these new
features, we can see the tools that they
have built in by default from the
beginning. We've got Booking.com, so you
can actually book hotel rooms straight
from ChatGpt. You've got Canva where it
can generate images directly inside of
ChatGpt, Corsera, Expedia, Figma,
Spotify, which we just demoed, and
Zillow. And then here's some of the apps
that are coming soon that you'll be able
to basically chat, interact with
directly from within ChatGpt. All
Trails, Door Dash, Khan Academy,
Instacart, Pelaton, Open Table, Target,
The Fork, Trip Adviser, Thumbtac, and
Uber, and even more coming soon. In
fact, ChatgPT has an SDK or software
development kit which is designed to
help people develop apps that will work
inside of ChatGpt. This to me seems like
a much much better, more powerful, more
integrated version of what the plugins
was that they announced a couple years
ago that never really caught on, but I
think that was because you had to go and
make extra connections to these plugins
and it was kind of a pain in the butt.
Now you just talk to the tool you want
to use and it will just try to access
that tool. much lower barrier for
anybody to actually use these tools.
Let's have it generate something in
Figma for us. Create an org chart in
Figma for a fictional AI company that
generates a billion dollars per year.
Let's see what it does. I didn't even at
Figma. And you can see basically it just
described what the org chart would look
like. But notice at the bottom here, it
gave me a little prompt that says use
Figma for the answer. So because I
didn't at Figma, it didn't do it with
Figma, but it suggested that I use
Figma. So now if I click this, you can
see that it added Figma as the tool, but
it also started to just go ahead and use
Figma. Now it's asking me to connect to
my Figma account. So I'll continue.
Approve. Figma is now connected. And a
few seconds later, it generated a org
chart in Figma and I can go full screen
without ever leaving chat GPT. I could
scroll around. I could zoom in on it. We
can see here's our CEO, Alex Chen, our
CPO, CFO, Cello, etc. it it built out
the org chart and all I did was prompt
it to do this. All right, cool. I could
either open this in Figma now, like so,
and it's in my Figma account. Or I could
make changes to it directly inside of
chat GPT. Add another layer of employees
to the org chart. Going to think for a
moment. Now it's generating a Fig Jam
diagram. And as we can see, it added
another layer of employees underneath. I
didn't do anything other than just tell
it to with chat. Now, let's call upon
Canva. I'm going to say use Canva. All
right, so now we've got Canva attached.
And we'll use the prompt use Canva to
create a flyer for a rock band called
Norc that has a concert on Halloween at
the North Park Observatory in San Diego
at 8:00 p.m. The flyer should include
someone playing the guitar and spooky
Halloween elements. Let's see what flyer
it makes for us. And about a minute
later, we've got four different flyers
here that we can take a peek at. Look at
this. Somebody playing the guitar with,
you know, some Halloween elements here.
Here's variation two that it created.
NORC concert Halloween night rock show
at North Park Observatory. Here's
another one. And here's another one. To
me, this is really fascinating because
it almost turns chat GPT into like what
feels like a team member that you can
just pass stuff over to take care of for
you. If you need something done in Figma
or something done in Canva, you could
basically treat it like a team member
and say, "Hey, go make this for me real
quick." And it will do it. And then if
you need tweaks to the thing that it
made, you just tell your team member,
"Hey, now go change this." and it will
go and do it. And more and more tools
are going to be rolled out into chat
GPT, including apps that people like you
watching this could build. They even
mentioned that they're probably going to
roll out some sort of monetization in
the future where if your app gets
integrated and gets used a lot, you'll
probably get paid for that usage, which
was one of the things they originally
planned on doing with the custom GPT
store that never totally panned out very
well. But again, because this is more
native and this is happening right
inside of the chat, it's much more
likely to get used, especially if
ChatGpt is going to recommend tools to
you. If I tell it to go and create me a
flyer, and then it says, "Hey, why don't
you make this flyer in Canva?" And I
say, "Okay, make it in Canva." It makes
it a lot easier to just fire up these
apps and use them inside of ChatGpt. And
I'm super excited to see what the like
developer community builds for this
because, you know, they're going to
build some really, really crazy
integrated apps directly into chat GPT
that do all sorts of cool workflows for
you. Now, if you want to use this
yourself, as far as I can tell, it's
rolled out for everyone. According to
OpenAI's own press release here, it does
say, "We worked with a small group of
early partners to launch the first set
of apps available in chat GPT today. I
don't see any restrictions on countries
or specific plans that that can or can't
use this feature. What if I told you
there's an AI video agent that combines
the creativity of an entire advertising
team with the power of VO3 and nano
banana combined? And what if I told you
that Starbucks spent nearly $600 million
on advertising worldwide in 2024? So,
let's combine those two thoughts. I want
to see if I can recreate a Starbucks
level ad for under a hundred bucks using
only this one AI tool. So, for this
experiment, I'm using Nvidia's new AI
video generation platform. It's
specifically designed for marketers who
want professionallook ads but don't have
the massive budgets of big brands. So
here's the prompt. Create a 25-se
secondond Starbucks ad for Strato
Frappuccino. I also uploaded some
reference images directly into Invido to
help guide the visuals. Once the script
and assets were added, I selected ultra
quality to give it that professional
look and clicked generate video. We back
again, y'all. How y'all been? It's
getting hot.
>> Pretty impressive for oneshotting it.
So, I'm just going to type into the edit
command box. Speed up the playback to
1.2x. And within minutes, the ad
regenerated with those changes applied.
Now, here's the finished Starbucks ad
created entirely with AI for under 100
bucks without leaving my room.
>> We back again, y'all. How y'all been?
It's getting hot. Hey, good ter
[Music]
[Applause]
[Music]
>> and honestly, it's kind of making me
crave some Starbucks right now. So, if
you're thinking about making highquality
ads without the huge budget, I
definitely recommend checking out
Nvidia's generative plan. The ultra
quality option is what really sets it
apart from other AI video generation
tools. So, check it out at the link in
the description box below. But like I
said before, that's just one of two
announcements that I thought was really
cool from DevDay. The other one was the
introduction of agent kit. And this is
the one that I feel like is really sort
of disruptive to a lot of companies. To
me, this seems similar to what NADN
does. Mind Studio, Lindy, Make.com,
Zapier. A lot of these tools have this
sort of like visual workflow builder
where you can connect tools and have it
call different AI agents and things like
that. And well, that's what this agent
kit does. It's a visual canvas for
creating envisioning multi- aent
workflows. And it's got what's called
chatkit, which allows you to embed it
within your own apps and websites as
well. So, you can build agents inside of
agent kit, connect them up to your app
or your website or something else, and
let other people run those agents. It
It's pretty wild. And you can see it's
this like visual workflow builder. If
you've used tools like NAN or Mind
Studio, you'll probably recognize a very
similar kind of workflow here. It also
leverages MCPS or model context
protocols, basically making it so any
other app on the internet can sort of
create their own MCP server and make it
so that that app could essentially tie
into this agent workflow builder. So,
right now you've got your tools like
Zapier and Make and Nad and Mind Studio
and all these tools and they integrate
with a ton of platforms, right? You're
not limited to just OpenAI's models. You
can basically connect them to anything
with an API. Well, this agent kit is
going to be very similar over time. More
and more companies are going to develop
MCPs for their product, meaning you'll
be able to tie them into tools like this
agent kit, but you'll probably always be
stuck using the OpenAI models. So, if
you really want to build these workflows
and use other models outside of OpenAI's
models, those other platforms are
probably still a bit better for that.
Now, if you want to use agent kit, this
one isn't actually in chat GPT. This one
is inside of their developer playground.
If you go to
platform.opai.com/agentbuilder,
that's where you'll see this new
agentbuilder that you can play with. And
there are a few templates that you can
use right off the bat. So, you've got
data enrichment, pull together data to
answer user questions, a planning
helper, a customer service bot,
structured data Q&A, document
comparison, internal knowledge
assistant, or you can create one from
scratch. And we can see here that we've
got a very similar nodebased workflow
just like all these other agent builders
that you've probably seen online. I
don't know about you, but this feels
pretty disruptive to a lot of those
tools with the main exception being that
this leverages only open AI models.
those other tools, you can basically
grab and use any models you want. So, we
can click on the start node here and we
can see that uh it's got an input
variable. So, if I was to preview this
right now, it probably asks for Yeah.
So, this is where you give your input
variable here. And then we click on my
agent and you can see the only
instructions it has is you're a helpful
assistant. It uses GPT5, but you can
select any of the OpenAI models that are
available. You can choose how much you
want it to reason. You can give it
access to various tools. You can change
how verbose it is. And again, if I was
to preview this right now, it would
probably act just like chat GPT with
nothing else. How are you today? And
that actually gives me nothing. It
actually threw up an error a second ago.
So maybe we do have to build this out a
little bit more. And right now it feels
like it's sort of designed for making
like chatbased workflows. It doesn't
seem like it's going to automate a whole
bunch of stuff behind the scenes yet.
There's not enough like triggers for it
to start with yet. It's like input
variables or you know feeding it
variables behind the scenes are
literally like the only two things you
can do right now for your input like
trigger. We could add a file search here
where we connect our nodes and then it
will actually query any files. So if we
upload documents like PDFs or doc files
or things like that, it can actually
query that document for an answer in the
chat that you output. You can add guard
rails. tell it what you do and don't
want people to be able to do with your
bot. So, you have the ability to make it
so it won't share any personally
identifiable information. And we can
change the settings on that, like don't
don't show credit card numbers or IP
addresses or people's names or whatever.
And you can have it sort of moderate
that before it even gets to the chat.
You can have it detect potential
hallucinations. You can have it detect
jailbreaks, all sorts of guardrails
before it even gets to the chat. You can
connect it up to various MCP servers.
This is where it starts to get like
infinitely scalable. Any product that
has an MCP server, you should be able to
connect it up. So, right now there's all
these built-in ones, you know, HubSpot,
Shopify, Gmail, Google Calendar, etc.
But if we click on plus server, we can
add MCP server details, which would be
provided by the company you're trying to
connect, and connect this into almost
any tool you can imagine. We could add
if else statements. So when somebody
gives their input, let's say if they ask
a question, let's see, let's say user
asks a question and we'll call the case
name just question. Then we can have it
actually branch off and go to one agent
and have this agent do something very
specific. If it's not a question, it's
more of a statement, we can create a
different agent response and have it
branch off to this agent. So if they ask
the bot a question, we can have it
answer the question. And this is a very
very basic example. If they don't ask a
question, just say reply and tell the
user we only answer questions. Please
ask a question. So again, this is very
early days for this agent kit. I imagine
we'll see these nodes build out a lot
and we'll see a lot of tools add MCP
just so that they can get connected to
tools like chatgpt and we're going to
see a whole ecosystem build out where
you can build these insane workflows.
Now, right now they're not quite up to
par with Mind Studio and NADN and tools
like that. Again, those just integrate
with so much more and you can choose
which AI models you want to use. But
man, this is getting really, really,
really close to that. And as this builds
out, I don't know, some of those
companies are going to have to figure
out how do we stand out among chat GPT
who can just potentially build our
features into their product. But here's
some examples that they showed during
dev day to kind of give you an idea of
what you can do with it. So they had a
website that explained the agenda for
dev day for everybody that was at
DevDay. And they built in real time on
the stage a chatbot that anybody can use
inside of that little agenda app that
they had. They uploaded all of the
details into this agent about the dev
day sessions and who was talking about
what, when, and where. And then if
somebody asked a question about what
they should go see, the agent would
query that information and suggest what
they should go and see at dev day. I
think it was a fairly simple and fairly
safe example that they knew would
probably work live. But you can see you
enter your question, it goes through
some guard rails. I believe the guard
rails that they passed it through is
they didn't want it to share any
personally identifiable information if
somebody asked for it. And so that was
the sort of pass fail. and then it would
categorize it based on the type of
question, pass it through an if else
statement. If they were asking about
session information, it would go to one
agent. And if it was something else, it
would go to a different agent. A really,
really simple agent that if you opened
up their little Devday app and asked
about what sessions, it would make sure
not to share any information it
shouldn't and then it would give you the
information about the various sessions
and the events. Very, very simple
workflow. Another example they shared on
their YouTube channel was this travel
agent that they made. So, if they asked
about flight info, it went to a flight
agent that would share details about the
flight. If it was something other than
flight info, it went to an itinerary
agent. And just for fun, she had it like
color the background based on where they
were traveling to. So, it decided that
yellow was the ideal color to show San
Francisco to H&D. I think she said that
was Tokyo. So, some pretty simple
workflows right now. But the bigger
implication is where these workflows are
headed. Once more and more companies
build out MCP servers that can connect
to these, you're going to be able to
build insane automations that somebody
gives it a prompt and it sends it to
this tool and then sends it to another
tool and sends it to another tool and
then messages somebody on Slack and then
notifies team members and then sends an
email. And we're going to be building
all these crazy automations that you
might do with like an NAND now just
directly inside of ChatGpt. And I
imagine if I had to guess, this is a
prediction, but if I had to guess,
they're going to allow you to build
these with natural language pretty soon,
too. Build me an agent that does X and
it will go and build out the nodebased
workflow based on the text prompt that
you gave it. So, really, really cool
stuff. Really fun stuff out of OpenAI.
I'm excited to see how this evolves.
Again, if you're not following me over
on Instagram, make sure you do that. I'm
giving away an iPhone 17 just for
following me on Instagram. Uh, we're
doing a competition giveaway, so head
over there. The link to Instagram's in
the description. Thank you so much to
Invido for sponsoring today. Really,
really appreciate you guys. If you like
videos like this, make sure you like
this one, subscribe to this channel, and
hopefully I'll see you in the next one.
Thank you so much for nerding out with
me today. If you like videos like this,
make sure to give it a thumbs up and
subscribe to this channel. I'll make
sure more videos like this show up in
your YouTube feed. And if you haven't
already, check out futuretools.io where
I share all the coolest AI tools and all
the latest AI news. And there's an
awesome free newsletter. Thanks again.
Really appreciate you. See you in the
next one.